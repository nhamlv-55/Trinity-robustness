{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "569cb6ff-64ab-4878-9ddb-efd45355e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(44)\n",
    "\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from data import get_othello, plot_probs, plot_mentals\n",
    "from data.othello import permit, start_hands, OthelloBoardState, permit_reverse\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.model import GPT, GPTConfig, GPTforProbeIA\n",
    "from mingpt.utils import sample, intervene, print_board\n",
    "from mingpt.probe_model import BatteryProbeClassification, BatteryProbeClassificationTwoLayer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649da7e-8be4-4fe8-95a1-ad9ebcbaf6ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load nonlinear probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71df94f2-2a1e-428d-ad7a-d6dfba10fbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatteryProbeClassificationTwoLayer(\n",
       "  (proj): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=256, out_features=192, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "championship = False\n",
    "mid_dim = 256\n",
    "how_many_history_step_to_use = 99\n",
    "exp = f\"state_tl{mid_dim}\"\n",
    "if championship:\n",
    "    exp += \"_championship\"\n",
    "\n",
    "\n",
    "probes = {}\n",
    "layer = 8\n",
    "probe = BatteryProbeClassificationTwoLayer(torch.cuda.current_device(), probe_class=3, num_task=64, mid_dim=mid_dim)\n",
    "load_res = probe.load_state_dict(torch.load(f\"./ckpts/battery_othello/{exp}/layer{layer}/checkpoint.ckpt\"))\n",
    "probe.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d64400-3b3b-46a2-a043-2bfa652beb7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load trained models for probing at layer 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "221302f7-638d-4887-adfa-bbadb44008d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 30.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created has 1 sequences, 61 unique words.\n"
     ]
    }
   ],
   "source": [
    "# othello = get_othello(ood_perc=.2, data_root=\"data/othello_pgn\", wthor=False)\n",
    "othello = get_othello(ood_perc=0., data_root=None, wthor=False, ood_num=1)\n",
    "train_dataset = CharDataset(othello)\n",
    "\n",
    "mconf = GPTConfig(61, 59, n_layer=8, n_head=8, n_embd=512)\n",
    "\n",
    "model = GPTforProbeIA(mconf, probe_layer=layer, disable_last_layer_norm = True)\n",
    "load_res = model.load_state_dict(torch.load(\"./ckpts/gpt_no_last_layer_norm.ckpt\"))\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    model = model.to(device)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9e5f7-725b-428c-b28b-6ee2cdd0cb73",
   "metadata": {},
   "source": [
    "## Validate it: for what percentage of all partial games in validation set, the top-1 prediction is legal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68012ea9-70b2-47af-bc79-c79c9ebac676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mem Used: 18.02 GB: 100%|██████████| 238/238 [01:15<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicating...\n",
      "Deduplicating finished with 23796010 games left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 20 million for training, 3796010 for validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99.93% pass rate: 13500/13509 among all searched nodes:  23%|██▎       | 229/1000 [01:40<05:37,  2.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d5799d4a70a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhole_game\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlength_of_partial_game\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/othello/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Trinity-robustness/othello_world/mingpt/utils.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(model, x, steps, temperature, sample, top_k)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mx_cond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# crop context if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# pluck the logits at the final step and scale by temperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/othello/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Trinity-robustness/othello_world/mingpt/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# each position maps to a (learnable) vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, T, f]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, T, # Words]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/othello/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/othello/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/othello/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Trinity-robustness/othello_world/mingpt/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_att, only_last)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_att\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mupdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monly_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mupdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/othello/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/othello/lib/python3.8/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    171\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/othello/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2203\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m         )\n\u001b[0;32m-> 2205\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not championship:  # for GPT trained on both datasets, use the validation set of synthetic for validation\n",
    "    othello = get_othello(ood_num=-1, data_root=None, wthor=True)\n",
    "\n",
    "total_nodes = 0\n",
    "success_nodes = 0\n",
    "\n",
    "bar = tqdm(othello.val[:1000])\n",
    "for whole_game in bar:\n",
    "    length_of_whole_game = len(whole_game)\n",
    "    for length_of_partial_game in range(1, length_of_whole_game):\n",
    "        total_nodes += 1\n",
    "        context = whole_game[:length_of_partial_game]\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None, ...].to(device)\n",
    "        y = sample(model, x, 1, temperature=1.0)[0]\n",
    "        completion = [train_dataset.itos[int(i)] for i in y if i != -1]\n",
    "        try:\n",
    "            OthelloBoardState().update(completion, prt=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "        else:\n",
    "            success_nodes += 1\n",
    "    bar.set_description(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")\n",
    "print(f\"{success_nodes/total_nodes*100:.2f}% pass rate: {success_nodes}/{total_nodes} among all searched nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833a2c54-8d2d-4d8d-9819-4da4b6536f32",
   "metadata": {},
   "source": [
    "## Load a game from intervention benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9b13d4a-b2a7-4312-8314-92e984109683",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"intervention_benchmark.pkl\", \"rb\") as input_file:\n",
    "    dataset = pickle.load(input_file)\n",
    "    \n",
    "case_id = 777\n",
    "completion = dataset[case_id][\"history\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1b033e-854a-45f2-a6a8-41969a6affe2",
   "metadata": {},
   "source": [
    "### Check the partial game progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96ac05c2-7de9-4eda-b130-a1dc2bce16b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 29, 18, 42, 19]\n",
      "--------------------\n",
      "[]\n",
      "a                \n",
      "b                \n",
      "c                \n",
      "d       O X      \n",
      "e       X O      \n",
      "f                \n",
      "g                \n",
      "h                \n",
      "  1 2 3 4 5 6 7 8\n",
      "--------------------\n",
      "--------------------\n",
      "['e6']\n",
      "a                \n",
      "b                \n",
      "c                \n",
      "d       O X      \n",
      "e       X X X    \n",
      "f                \n",
      "g                \n",
      "h                \n",
      "  1 2 3 4 5 6 7 8\n",
      "--------------------\n",
      "--------------------\n",
      "['e6', 'd6']\n",
      "a                \n",
      "b                \n",
      "c                \n",
      "d       O O O    \n",
      "e       X X X    \n",
      "f                \n",
      "g                \n",
      "h                \n",
      "  1 2 3 4 5 6 7 8\n",
      "--------------------\n",
      "--------------------\n",
      "['e6', 'd6', 'c3']\n",
      "a                \n",
      "b                \n",
      "c     X          \n",
      "d       X O O    \n",
      "e       X X X    \n",
      "f                \n",
      "g                \n",
      "h                \n",
      "  1 2 3 4 5 6 7 8\n",
      "--------------------\n",
      "--------------------\n",
      "['e6', 'd6', 'c3', 'f3']\n",
      "a                \n",
      "b                \n",
      "c     X          \n",
      "d       X O O    \n",
      "e       O X X    \n",
      "f     O          \n",
      "g                \n",
      "h                \n",
      "  1 2 3 4 5 6 7 8\n",
      "--------------------\n",
      "--------------------\n",
      "['e6', 'd6', 'c3', 'f3', 'c4']\n",
      "a                \n",
      "b                \n",
      "c     X X        \n",
      "d       X X O    \n",
      "e       O X X    \n",
      "f     O          \n",
      "g                \n",
      "h                \n",
      "  1 2 3 4 5 6 7 8\n",
      "--------------------\n",
      "valid moves: ['b4', 'c6', 'd3', 'e7', 'f4', 'f6']\n"
     ]
    }
   ],
   "source": [
    "print(completion)\n",
    "ab = OthelloBoardState()\n",
    "ab.update(completion, prt=True)\n",
    "\n",
    "pre_intv_valids = [permit_reverse(_) for _ in ab.get_valid_moves()]\n",
    "print(\"valid moves:\", pre_intv_valids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd12f2c4-b89c-41a3-acdd-3f48123d6894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: \n",
      " tensor([[34, 28, 19, 39, 20]], device='cuda:0') torch.Size([1, 5])\n",
      "h: \n",
      " tensor([-0.8545, -0.5327, -0.4665, -0.9722,  1.9432,  1.0412, -0.2281,  2.2611,\n",
      "        -0.8041, -0.3103], device='cuda:0', grad_fn=<SliceBackward>) torch.Size([1, 5, 512])\n",
      "output by running head(h):\n",
      " tensor([-24.7494,  -1.8201,  -2.2122,  -1.0959,  -2.1191,  -0.8590,  -1.0885,\n",
      "         -2.1869,  -1.5516,  -1.3359], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>) torch.Size([1, 5, 61])\n",
      "output by running the model(s):\n",
      " tensor([-24.7494,  -1.8201,  -2.2122,  -1.0959,  -2.1191,  -0.8590,  -1.0885,\n",
      "         -2.1869,  -1.5516,  -1.3359], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>) torch.Size([1, 5, 61])\n",
      "reconstructed board:\n",
      " tensor([[ -9.0074,  12.0080,  -5.6608],\n",
      "        [-13.9133,  18.9850,  -8.2382],\n",
      "        [-11.3246,  17.7782,  -6.7344],\n",
      "        [-10.4789,  19.8135,  -8.0795],\n",
      "        [ -8.3978,  15.3387,  -7.0764],\n",
      "        [ -7.8179,  16.5528,  -5.1594],\n",
      "        [-12.8687,  12.0632,  -8.3205],\n",
      "        [-11.3539,  10.4207,  -8.9608],\n",
      "        [-12.1934,  14.1372,  -9.3510],\n",
      "        [-11.7111,  15.3484,  -6.1864]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward>)\n",
      "[[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 2, 2, 1, 1, 1, 1], [1, 1, 1, 2, 2, 0, 1, 1], [1, 1, 1, 0, 2, 2, 1, 1], [1, 1, 0, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "|        |\n",
      "|        |\n",
      "|  XX    |\n",
      "|   XXO  |\n",
      "|   OXX  |\n",
      "|  O     |\n",
      "|        |\n",
      "|        |\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    print(model)\n",
    "\n",
    "s = torch.tensor([train_dataset.stoi[move] for move in completion], dtype=torch.long).to(device)\n",
    "s = s[None, :]\n",
    "print(\"s: \\n\", s, s.shape)\n",
    "\n",
    "h = model.forward_1st_stage(s)\n",
    "print(\"h: \\n\", h[0][-1][:10], h.shape)\n",
    "\n",
    "out1 = model.head(h)\n",
    "print(\"output by running head(h):\\n\", out1[0][-1][:10], out1.shape)\n",
    "\n",
    "out2, _ = model(s)\n",
    "print(\"output by running the model(s):\\n\", out2[0][-1][:10], out2.shape)\n",
    "\n",
    "reconstructed_board, _ = probe((h)[0][-1])\n",
    "print(\"reconstructed board:\\n\", reconstructed_board.squeeze()[:10])\n",
    "board = torch.argmax(reconstructed_board.squeeze(), dim = -1).reshape(8,8).tolist()\n",
    "print(board)\n",
    "\n",
    "\"\"\"\n",
    "['e6', 'd6', 'c3', 'f3', 'c4']\n",
    "a                \n",
    "b                \n",
    "c     X X        \n",
    "d       X X O    \n",
    "e       O X X    \n",
    "f     O          \n",
    "g                \n",
    "h                \n",
    "  1 2 3 4 5 6 7 8\n",
    "\"\"\"\n",
    "for r in board:\n",
    "    print(\"|\", end='')\n",
    "    for c in r:\n",
    "        if c == 1:\n",
    "            print(\" \", end='')\n",
    "        elif c==0:\n",
    "            print(\"O\", end='')\n",
    "        elif c==2:\n",
    "            print(\"X\", end='')\n",
    "\n",
    "    print(\"|\\n\", end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604e9657-7185-4177-8545-a40aeafaf3a8",
   "metadata": {},
   "source": [
    "### Extract the latent space, the head, and the probe to be used for Marabou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3085ce54-e86e-4df4-98c0-f0958ced59c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([61]) torch.Size([192])\n",
      "tensor([-2.4749e+01, -1.8201e+00, -2.2122e+00, -1.0959e+00, -2.1191e+00,\n",
      "        -8.5902e-01, -1.0885e+00, -2.1869e+00, -1.5516e+00, -1.3359e+00,\n",
      "         1.6450e-02, -1.2670e+00,  8.7403e+00, -8.7246e-01, -1.0914e+00,\n",
      "        -2.0707e+00, -9.6828e-01, -2.3762e+00,  6.2370e-01, -1.1780e+00,\n",
      "        -7.2599e-01, -1.2089e-01,  8.9860e+00, -4.0348e-02, -1.5985e+00,\n",
      "        -5.2786e-01, -1.0326e+00,  8.9397e+00,  9.1746e-01,  1.3736e-01,\n",
      "        -1.4051e+00, -1.2508e+00, -8.6213e-01, -2.8386e+00, -7.0979e-01,\n",
      "         8.7975e+00, -2.5311e+00, -7.8931e-01, -1.6974e+00, -3.0895e+00,\n",
      "         9.0381e+00, -2.4195e-01,  8.8705e+00, -1.7676e+00, -1.3732e+00,\n",
      "        -2.6736e+00, -1.6396e+00, -1.4218e+00, -8.4368e-01, -2.0650e+00,\n",
      "        -3.7264e-01, -1.4883e+00, -2.9299e+00, -8.5015e-01, -2.1101e+00,\n",
      "        -6.4349e-01, -2.5108e+00, -3.8076e-01, -1.9649e+00, -8.7731e-01,\n",
      "        -1.6228e+00, -9.0074e+00,  1.2008e+01, -5.6608e+00, -1.3913e+01,\n",
      "         1.8985e+01, -8.2382e+00, -1.1325e+01,  1.7778e+01, -6.7344e+00,\n",
      "        -1.0479e+01,  1.9814e+01, -8.0795e+00, -8.3978e+00,  1.5339e+01,\n",
      "        -7.0764e+00, -7.8179e+00,  1.6553e+01, -5.1594e+00, -1.2869e+01,\n",
      "         1.2063e+01, -8.3205e+00, -1.1354e+01,  1.0421e+01, -8.9608e+00,\n",
      "        -1.2193e+01,  1.4137e+01, -9.3510e+00, -1.1711e+01,  1.5348e+01,\n",
      "        -6.1864e+00, -3.9247e+00,  1.4622e+01, -1.7170e+00, -4.6614e+00,\n",
      "         3.1614e+01, -2.7786e+00, -3.2183e+00,  1.6265e+01, -2.4705e+00,\n",
      "        -1.7210e+00,  1.3584e+01, -1.7333e+00, -8.8276e+00,  1.6482e+01,\n",
      "        -8.5950e+00, -7.7397e+00,  1.4906e+01, -8.3877e+00, -6.4482e+00,\n",
      "         1.1211e+01, -6.8653e+00, -5.5668e+00,  1.7689e+01, -3.3056e+00,\n",
      "        -2.7474e+00, -2.2941e+00,  1.9073e+00, -2.3331e+00, -1.4801e+01,\n",
      "         1.1955e+00,  8.5686e-01,  1.4723e+01,  2.0662e+00, -3.8298e-03,\n",
      "         3.0280e+01, -1.7946e+00, -4.3270e+00,  1.2099e+01, -6.0945e+00,\n",
      "        -6.6530e+00,  9.8442e+00, -7.1608e+00, -8.2914e+00,  1.7911e+01,\n",
      "        -6.8088e+00, -2.4002e+00,  1.2447e+01, -2.6098e+00, -1.8512e+00,\n",
      "         3.9807e+01, -1.0150e+00,  7.8814e+00, -1.6897e+01,  1.1095e+01,\n",
      "         4.7185e+00, -1.8463e+01,  1.0206e+01,  2.2371e+00, -1.6226e+01,\n",
      "        -1.1755e+00, -3.8696e+00,  1.1172e+01, -4.0217e+00, -6.9604e+00,\n",
      "         1.4140e+01, -5.9777e+00, -6.8886e+00,  6.4720e+00, -5.6706e+00,\n",
      "        -3.1305e+00,  9.8391e+00, -4.6636e+00,  8.0188e-01,  8.1533e+00,\n",
      "        -1.0020e+00,  1.0475e+01, -1.6713e+01,  8.7406e+00,  6.1430e+00,\n",
      "        -1.8591e+01,  8.6842e+00, -9.5724e-01, -1.4339e+01,  3.7878e+00,\n",
      "        -7.1277e+00,  2.6785e+01, -4.3826e+00, -7.4928e+00,  1.4807e+01,\n",
      "        -4.2453e+00, -6.6218e+00,  1.4638e+01, -6.6681e+00, -5.9502e+00,\n",
      "         7.6199e+00, -6.7153e+00,  7.6264e-01, -9.6702e+00, -1.4942e+00,\n",
      "        -4.6576e-01,  2.9825e+01, -4.7499e+00, -4.0595e-01,  1.0471e+01,\n",
      "         5.6533e-01, -6.2962e+00,  2.4299e+01, -3.4646e+00, -7.1712e+00,\n",
      "         1.2964e+01, -2.8427e+00, -6.1597e+00,  9.1665e+00, -3.4736e+00,\n",
      "        -1.1561e+01,  1.1093e+01, -1.0398e+01, -8.6734e+00,  1.3180e+01,\n",
      "        -9.4349e+00, -6.0133e+00,  7.1758e+00, -6.9573e+00, -2.6107e+00,\n",
      "         1.2454e+01, -5.3159e+00, -2.1724e+00,  8.5538e+00, -2.6688e+00,\n",
      "        -4.4248e+00,  5.9117e+00, -5.2250e+00, -9.7728e+00,  1.3065e+01,\n",
      "        -9.8479e+00, -1.1491e+01,  1.6901e+01, -8.7649e+00, -9.7413e+00,\n",
      "         1.3841e+01, -8.6794e+00, -8.1847e+00,  1.0367e+01, -1.0168e+01,\n",
      "        -6.5317e+00,  1.4873e+01, -7.2492e+00, -6.8074e+00,  1.2133e+01,\n",
      "        -7.6538e+00, -5.8391e+00,  1.1224e+01, -6.0314e+00, -8.2537e+00,\n",
      "         1.6752e+01, -8.5709e+00, -7.8803e+00,  1.3102e+01, -8.0266e+00,\n",
      "        -1.3228e+01,  1.4578e+01, -9.7353e+00], device='cuda:0',\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "class TrinityNet(nn.Module):\n",
    "    def __init__(self, probe, head, n_embd = 512, vocab_size = 61, mid_dim = 256):\n",
    "        super().__init__()\n",
    "        #the probe head\n",
    "        self.probe = nn.Sequential(\n",
    "            nn.Linear(n_embd, mid_dim, bias=True),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(mid_dim, 64*3, bias=True),\n",
    "        )\n",
    "        #set weight\n",
    "        with torch.no_grad():\n",
    "            self.probe[0].weight = nn.Parameter(probe.proj[0].weight)\n",
    "            self.probe[0].bias = nn.Parameter(probe.proj[0].bias)\n",
    "            \n",
    "            self.probe[2].weight = nn.Parameter(probe.proj[2].weight)\n",
    "            self.probe[2].bias = nn.Parameter(probe.proj[2].bias)\n",
    "        #the logits head\n",
    "        self.head = nn.Linear(n_embd, vocab_size, bias=False)\n",
    "        #set weight\n",
    "        with torch.no_grad():\n",
    "            self.head.weight = nn.Parameter(head.weight)\n",
    "        \n",
    "    def forward(self, h):\n",
    "        logits = self.head(h)\n",
    "        probe = self.probe(h)\n",
    "        print(logits.shape, probe.shape)\n",
    "        return torch.cat([logits, probe])\n",
    "    \n",
    "    def get_a_board(self):\n",
    "        return OthelloBoardState()\n",
    "    \n",
    "    def play(self, s, is_i= True):\n",
    "        if isinstance(s, torch.Tensor):\n",
    "            s = s.squeeze().cpu().numpy()\n",
    "        if is_i:\n",
    "            #convert to s\n",
    "            s = [train_dataset.itos[move] for move in s]\n",
    "        print(\"playing the sequence:\",s)\n",
    "        board = self.get_a_board()\n",
    "        board.update(s, prt=True)\n",
    "    \n",
    "trinity = TrinityNet(probe, model.head)\n",
    "trinity.to(device)\n",
    "\n",
    "print(trinity(h[0][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dae6225a-3950-4352-a32a-2eb763db8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import maraboupy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
